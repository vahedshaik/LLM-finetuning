# LLM-finetuning

**Part-A:** Simple Agents assignment - Build a very simple python agent

**Colab link:** https://colab.research.google.com/drive/1V-x_fX-WKJXwM97dwuv_ir8EUNWTebp4?usp=sharing

**Part-B:** Implemented auto agent

**Colab link:** https://colab.research.google.com/drive/1scm7eqiNPNvWHbP5x73YO6ov_e8XpsuK?usp=sharing

**Part-C:** Finetune LLM for your custom task, Use Lora to finetune the model

**Colab link:** https://colab.research.google.com/drive/1SUn_cjX6xZkrQh4Fh4QkWTeUTrQ28pUO?usp=sharing

**Part-D:** Used QLora to finetune a model by generating custom data set.

**Colab link:** https://colab.research.google.com/drive/1pj0L1z-Q4CjDRKONslZl3GcS3PkqtnpC?usp=sharing

**Part-E:** Use mistral llm with RAG and demonstrated a production usecase

**Colab link:** https://colab.research.google.com/drive/1peyIlr2f2nXLKlQvo3tbqg8v5PuUDrE2?usp=sharing

**Part-F:** Integrated mistral model as backend with langchain

**Colab link:** https://colab.research.google.com/drive/1-UZg3H97nHF7cD8i3TwPvfnISCXgPgjI?usp=sharing

**Part-G:** Quantize llm with ggml and gguf and build an end2end chat application on mobile phone and load the model and demonstrate using MLC end2end.

**Colab link:** https://colab.research.google.com/drive/1EAz9MObVbcdj2o-I4ukFxoZ2Dhx9fW_5?usp=sharing
**Colab link:** https://colab.research.google.com/drive/1gbs0NK8vOcZX73vqGxPP8viziiOcb5v6?usp=sharing

**Part-H:** Use LLM studio and LLM Data Studio to demonstrate data set generation, fine tuning, deployment to huggingface and inference (Gradio)

**Colab link:** https://colab.research.google.com/drive/12Pms1rvCrG8mFzXzONkeGx-CSUTFFmb4?usp=sharing
